{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of CNN_catordog ver1 was not as good as we want.\n",
    "\n",
    "We can make this NN deeper to improve our model's performance.\n",
    "\n",
    "How to make it deeper?\n",
    "###    There are two ways to do:\n",
    "-    1. add the second convolutional layer\n",
    "-    2. add another fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 : Build a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the keras libraries and packages\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1 : Convolution layer\n",
    "model.add(Convolution2D(32,(3,3), input_shape=(128,128,3), activation='relu' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2 : Pooling layer : in oder to reduce the numbers of input nodes before flatten this to a large vector\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ------- The second Convolutional layer -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(64,(3,3), activation='relu' ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# If have GPU, you can try Convolution2D(64, (3,3)...), and add the third Convolution Layer, then 128 ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(128,(3,3), activation='relu' ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step3: Flatten\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step4 : Fully connected layer as hidden layer\n",
    "model.add(Dense(activation=\"relu\", units=128))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units = 1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the CNN\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,304,769\n",
      "Trainable params: 3,304,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2 : Fit the CNN to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: preprocessing the images\n",
    "# Before fit the  model, proceed to image augmentation (consists of pre-processing images) to prevent overfitting\n",
    "# data augmentation: random transformation on a random selection of images, like rotation, flipping, shifting, shearing...\n",
    "# data augmentation functions: 1-enrich datasets without adding more images,\n",
    "#                              2-reduce overfitting with a small amount of images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (128, 128),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (128, 128),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "# target_size = (64, 64), If want better performance, here can use big images, like 128,128\n",
    "# the bigger the images are, the more information they can contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "8000/8000 [==============================] - 1468s 184ms/step - loss: 0.3233 - acc: 0.8477 - val_loss: 0.3771 - val_acc: 0.8720\n",
      "Epoch 2/12\n",
      "8000/8000 [==============================] - 1466s 183ms/step - loss: 0.0989 - acc: 0.9620 - val_loss: 0.6799 - val_acc: 0.8583\n",
      "Epoch 3/12\n",
      "8000/8000 [==============================] - 1465s 183ms/step - loss: 0.0539 - acc: 0.9804 - val_loss: 0.7469 - val_acc: 0.8435\n",
      "Epoch 4/12\n",
      "8000/8000 [==============================] - 1469s 184ms/step - loss: 0.0376 - acc: 0.9865 - val_loss: 0.8444 - val_acc: 0.8460\n",
      "Epoch 5/12\n",
      "8000/8000 [==============================] - 1472s 184ms/step - loss: 0.0305 - acc: 0.9892 - val_loss: 0.8360 - val_acc: 0.8555\n",
      "Epoch 6/12\n",
      "8000/8000 [==============================] - 1470s 184ms/step - loss: 0.0249 - acc: 0.9912 - val_loss: 0.7876 - val_acc: 0.8710\n",
      "Epoch 7/12\n",
      "8000/8000 [==============================] - 1470s 184ms/step - loss: 0.0211 - acc: 0.9928 - val_loss: 0.8606 - val_acc: 0.8601\n",
      "Epoch 8/12\n",
      "8000/8000 [==============================] - 1465s 183ms/step - loss: 0.0189 - acc: 0.9937 - val_loss: 0.9781 - val_acc: 0.8566\n",
      "Epoch 9/12\n",
      "8000/8000 [==============================] - 1465s 183ms/step - loss: 0.0163 - acc: 0.9946 - val_loss: 0.7652 - val_acc: 0.8715\n",
      "Epoch 10/12\n",
      "8000/8000 [==============================] - 1464s 183ms/step - loss: 0.0148 - acc: 0.9949 - val_loss: 0.8466 - val_acc: 0.8609\n",
      "Epoch 11/12\n",
      "8000/8000 [==============================] - 1465s 183ms/step - loss: 0.0138 - acc: 0.9955 - val_loss: 0.8436 - val_acc: 0.8728\n",
      "Epoch 12/12\n",
      "8000/8000 [==============================] - 1469s 184ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.8716 - val_acc: 0.8654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee32922f98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step2: fit and test the performance\n",
    "model.fit_generator(training_set,\n",
    "                    steps_per_epoch = 8000,\n",
    "                    epochs = 12,\n",
    "                    validation_data = test_set,\n",
    "                    validation_steps = 2000)\n",
    "# epochs = 5, cause my mac is sucks. It costs my mac pro the whole day to train 5 epoches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNN2_catordog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'coreml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0d3188561b87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcoreml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'coreml'"
     ]
    }
   ],
   "source": [
    "import coreml\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
