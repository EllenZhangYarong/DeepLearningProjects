{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of CNN_catordog ver1 was not as good as we want.\n",
    "\n",
    "We can make this NN deeper to improve our model's performance.\n",
    "\n",
    "How to make it deeper?\n",
    "###    There are two ways to do:\n",
    "-    1. add the second convolutional layer\n",
    "-    2. add another fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 : Build a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the keras libraries and packages\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step1 : Convolution layer\n",
    "model.add(Convolution2D(32,(3,3), input_shape=(64,64,3), activation='relu' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step2 : Pooling layer : in oder to reduce the numbers of input nodes before flatten this to a large vector\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ------- The second Convolutional layer -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3), activation='relu' ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# If have GPU, you can try Convolution2D(64, (3,3)...), and add the third Convolution Layer, then 128 ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step3: Flatten\n",
    "model.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step4 : Fully connected layer as hidden layer\n",
    "model.add(Dense(activation=\"relu\", units=128))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units = 1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the CNN\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 813,217\n",
      "Trainable params: 813,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2 : Fit the CNN to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step1: preprocessing the images\n",
    "# Before fit the  model, proceed to image augmentation (consists of pre-processing images) to prevent overfitting\n",
    "# data augmentation: random transformation on a random selection of images, like rotation, flipping, shifting, shearing...\n",
    "# data augmentation functions: 1-enrich datasets without adding more images,\n",
    "#                              2-reduce overfitting with a small amount of images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "# target_size = (64, 64), If want better performance, here can use big images, like 128,128\n",
    "# the bigger the images are, the more information they can contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 2837s - loss: 0.3693 - acc: 0.8271 - val_loss: 0.4948 - val_acc: 0.8104\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 2811s - loss: 0.1408 - acc: 0.9448 - val_loss: 0.6677 - val_acc: 0.8280\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 3158s - loss: 0.0770 - acc: 0.9717 - val_loss: 0.7857 - val_acc: 0.8271\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 2824s - loss: 0.0562 - acc: 0.9799 - val_loss: 0.8147 - val_acc: 0.8323\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 2791s - loss: 0.0450 - acc: 0.9844 - val_loss: 0.9163 - val_acc: 0.8225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12003d908>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step2: fit and test the performance\n",
    "model.fit_generator(training_set,\n",
    "                    steps_per_epoch = 8000,\n",
    "                    epochs = 5,\n",
    "                    validation_data = test_set,\n",
    "                    validation_steps = 2000)\n",
    "# epochs = 5, cause my mac is sucks. It costs my mac pro the whole day to train 5 epoches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('CNN2_catordog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
