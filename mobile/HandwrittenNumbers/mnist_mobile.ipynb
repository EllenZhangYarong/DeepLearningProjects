{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# (Making sure) Set backend as tensorflow\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11419648/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Define some variables\n",
    "num_rows = 28\n",
    "num_cols = 28\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "# Import data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_cols, num_channels).astype(np.float32) / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_cols, num_channels).astype(np.float32) / 255\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "68s - loss: 0.6060 - acc: 0.7999 - val_loss: 0.1283 - val_acc: 0.9638\n",
      "Epoch 2/10\n",
      "67s - loss: 0.1798 - acc: 0.9431 - val_loss: 0.0832 - val_acc: 0.9768\n",
      "Epoch 3/10\n",
      "67s - loss: 0.1292 - acc: 0.9592 - val_loss: 0.0655 - val_acc: 0.9820\n",
      "Epoch 4/10\n",
      "62s - loss: 0.1086 - acc: 0.9659 - val_loss: 0.0495 - val_acc: 0.9855\n",
      "Epoch 5/10\n",
      "62s - loss: 0.0938 - acc: 0.9705 - val_loss: 0.0466 - val_acc: 0.9868\n",
      "Epoch 6/10\n",
      "62s - loss: 0.0828 - acc: 0.9734 - val_loss: 0.0415 - val_acc: 0.9881\n",
      "Epoch 7/10\n",
      "62s - loss: 0.0781 - acc: 0.9748 - val_loss: 0.0398 - val_acc: 0.9874\n",
      "Epoch 8/10\n",
      "62s - loss: 0.0683 - acc: 0.9783 - val_loss: 0.0349 - val_acc: 0.9885\n",
      "Epoch 9/10\n",
      "62s - loss: 0.0651 - acc: 0.9795 - val_loss: 0.0331 - val_acc: 0.9897\n",
      "Epoch 10/10\n",
      "62s - loss: 0.0614 - acc: 0.9804 - val_loss: 0.0320 - val_acc: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cbdf8d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model for inference\n",
    "for k in model.layers:\n",
    "    if type(k) is keras.layers.Dropout:\n",
    "        model.layers.remove(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('handWritten.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : conv2d_1_input, <keras.engine.topology.InputLayer object at 0x12d3a9810>\n",
      "1 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x12d3a9850>\n",
      "2 : conv2d_1__activation__, <keras.layers.core.Activation object at 0x12f0949d0>\n",
      "3 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x12d3ffbd0>\n",
      "4 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x12d3ff0d0>\n",
      "5 : conv2d_2__activation__, <keras.layers.core.Activation object at 0x12f3f4550>\n",
      "6 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x12d44cb10>\n",
      "7 : conv2d_3, <keras.layers.convolutional.Conv2D object at 0x12e3622d0>\n",
      "8 : conv2d_3__activation__, <keras.layers.core.Activation object at 0x12f107f10>\n",
      "9 : max_pooling2d_3, <keras.layers.pooling.MaxPooling2D object at 0x12d469cd0>\n",
      "10 : flatten_1, <keras.layers.core.Flatten object at 0x12e3adc90>\n",
      "11 : dense_1, <keras.layers.core.Dense object at 0x12e39f710>\n",
      "12 : dense_1__activation__, <keras.layers.core.Activation object at 0x12eb35890>\n",
      "13 : dense_2, <keras.layers.core.Dense object at 0x12e3cba10>\n",
      "14 : dense_2__activation__, <keras.layers.core.Activation object at 0x12eaf7890>\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "# Core ML has 2 set of APIs Vision API and Natural Language API\n",
    "output_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "scale = 1/255.\n",
    "coreml_model = coremltools.converters.keras.convert('./handWritten.h5',\n",
    "                                                    input_names='image',\n",
    "                                                    image_input_names='image',\n",
    "                                                    output_names='output',\n",
    "                                                    class_labels= output_labels,\n",
    "                                                    image_scale=scale)\n",
    "coreml_model.author = 'Gerardo Lopez Falcon'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = 'Model to classify hand written digit'\n",
    "coreml_model.input_description['image'] = 'Grayscale image of hand written digit'\n",
    "coreml_model.output_description['output'] = 'Predicted digit'\n",
    "\n",
    "coreml_model.save('handWritten.mlmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Creating an IOS app with Core ML from scratch!] https://medium.com/towards-data-science/creating-an-ios-app-with-core-ml-from-scratch-b9e13e8af9cb\n",
    "- [Now make your iOS apps intelligent!] https://medium.com/@aniket.ghode/now-make-your-ios-apps-intelligent-50c24903ffed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
