{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import gc\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 . Create Dataset -- add random noise pics into MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data() \n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test  = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_add_noise_50(X_train,y_train):\n",
    "    noise_random = np.random.rand(50000,32,32,3)\n",
    "    noise_labels = np.full((50000,1), 100, dtype=int)\n",
    "    X_train_50 = np.concatenate((X_train, noise_random), axis = 0 )\n",
    "    y_train_50 = np.concatenate((y_train, noise_labels), axis = 0 )\n",
    "    \n",
    "    return X_train_50,y_train_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_add_noise_5(X_train,y_train):\n",
    "    noise_random_5 = np.random.rand(500,32,32,3)\n",
    "    noise_labels_5 = np.full((500,1), 100, dtype=int)\n",
    "    \n",
    "    X_train_5 = np.concatenate((X_train, noise_random_5), axis = 0 )\n",
    "    y_train_5 = np.concatenate((y_train, noise_labels_5), axis = 0 )\n",
    "    \n",
    "    return X_train_5,y_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_me(X_train,y_train):\n",
    "    ind_list = [i for i in range(len(X_train))]\n",
    "    np.random.shuffle(ind_list)\n",
    "    X_train  = X_train[ind_list, :,:,:]\n",
    "    y_train = y_train[ind_list,]\n",
    "    \n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_style_ds(X_train, X_test, y_train, y_test,original):\n",
    "# keras - input\n",
    "\n",
    "    if(original == 1):\n",
    "        num_classes = 100               \n",
    "    else:\n",
    "        num_classes = 101\n",
    "        \n",
    "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 . Build Model -- keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, test_data,accs,losses):\n",
    "        self.test_data = test_data\n",
    "        self.accs = accs\n",
    "        self.losses = losses\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        accs.append(acc)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingByLossVal(keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='val_loss', patience=10, mode='auto', min_delta=0.01, verbose=0):\n",
    "        super(keras.callbacks.Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            print(\"Early stopping requires %s available!\" % self.monitor)\n",
    "            exit()\n",
    "\n",
    "        if current < self.min_delta:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_factory():\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     data_format='channels_last',\n",
    "                     input_shape=(32, 32, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_factory()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train no random noise added\n",
    "hs_mnist_no_scores = []\n",
    "hs_mnist_no_history= []\n",
    "for i in range(1):\n",
    "    X_train_no,y_train_no = X_train,y_train\n",
    "    X_train_no,y_train_no = shuffle_me(X_train_no,y_train_no)\n",
    "    X_train_no, X_test_no, y_train_no, y_test_no, num_classes = keras_style_ds(X_train_no, X_test, \n",
    "                                                                               y_train_no, y_test, 1)\n",
    "\n",
    "    history_loss_no = LossHistory()\n",
    "    early_stopping_no = EarlyStoppingByLossVal()\n",
    "    accs = []\n",
    "    losses = []\n",
    "    test_acc_loss_no = TestCallback([X_test_no, y_test_no],accs,losses)\n",
    "\n",
    "    model = model_factory()\n",
    "#     model.summary()\n",
    "    \n",
    "    history_no = model.fit(X_train_no, y_train_no, \n",
    "                           epochs=100, batch_size=32,\n",
    "                           validation_split=0.1,verbose=1,\n",
    "                           callbacks=[history_loss_no,early_stopping_no,test_acc_loss_no])\n",
    "    hs_mnist_no_history.append(history_no)\n",
    "    \n",
    "    model.save(\"./models/CIFAR_dnn_all_convergen_validation10_test_0425_no_%d.h5\" % (i+1))\n",
    "    \n",
    "    print()\n",
    "    print(test_acc_loss_no.accs)\n",
    "    print(test_acc_loss_no.losses)\n",
    "    \n",
    "    print()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with 60,000 random noise added\n",
    "hs_mnist_50_scores = []\n",
    "hs_mnist_50_history= []\n",
    "for h in range(1):\n",
    "    \n",
    "    X_train_50,y_train_50 = gen_add_noise_50(X_train,y_train)\n",
    "    X_train_50,y_train_50 = shuffle_me(X_train_50,y_train_50)\n",
    "    X_train_50, X_test_50, y_train_50, y_test_50, num_classes = keras_style_ds(X_train_50, X_test, \n",
    "                                                                               y_train_50, y_test, 0)\n",
    "    \n",
    "    accs = []\n",
    "    losses = []\n",
    "    \n",
    "    history_loss_50 = LossHistory()\n",
    "    early_stopping_50 = EarlyStoppingByLossVal() \n",
    "    test_acc_loss_50 = TestCallback([X_test_50, y_test_50], accs, losses)\n",
    "    \n",
    "    model_50 = model_factory()\n",
    "#     model_60.summary()\n",
    "    \n",
    "    history_50 = model_50.fit(X_train_50, y_train_50, \n",
    "                              epochs=100, batch_size=32,\n",
    "                              validation_split=0.1,verbose=1,\n",
    "                             callbacks=[history_loss_50,early_stopping_50,test_acc_loss_50])\n",
    "    hs_mnist_50_history.append(history_50)\n",
    "    \n",
    "    model_50.save(\"./models/CIFAR_dnn_all_convergen_validation10_test_0425_50_test_%d.h5\" % (h+1))\n",
    "\n",
    "    print()\n",
    "    print(test_acc_loss_50.accs)\n",
    "    print(test_acc_loss_50.losses)\n",
    "    print()\n",
    "   \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with 50,000 random noise added\n",
    "hs_mnist_5_history= []\n",
    "for h in range(1):\n",
    "    \n",
    "    X_train_5,y_train_5 = gen_add_noise_5(X_train,y_train)\n",
    "    X_train_5,y_train_5 = shuffle_me(X_train_5,y_train_5)\n",
    "    X_train_5, X_test_5, y_train_5, y_test_5, num_classes = keras_style_ds(X_train_5, X_test, \n",
    "                                                                           y_train_5, y_test, 0)\n",
    "    \n",
    "    accs = []\n",
    "    losses = []\n",
    "    \n",
    "    history_loss_5 = LossHistory()\n",
    "    early_stopping_5 = EarlyStoppingByLossVal() \n",
    "    test_acc_loss_5 = TestCallback([X_test_5, y_test_5], accs, losses)\n",
    "    \n",
    "    model_5 = model_factory()\n",
    "#     model_60.summary()\n",
    "    \n",
    "    history_5 = model_5.fit(X_train_5, y_train_5, \n",
    "                              epochs=100, batch_size=32,\n",
    "                              validation_split=0.1,verbose=1,\n",
    "                             callbacks=[history_loss_5,early_stopping_5,test_acc_loss_5])\n",
    "    hs_mnist_5_history.append(history_5)\n",
    "    \n",
    "    model_5.save(\"./models/CIFAR_dnn_all_convergen_validation10_test_0425_5_test_%d.h5\" % (h+1))\n",
    "\n",
    "    print()\n",
    "    print(test_acc_loss_5.accs)\n",
    "    print(test_acc_loss_5.losses)\n",
    "    print()\n",
    "   \n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
